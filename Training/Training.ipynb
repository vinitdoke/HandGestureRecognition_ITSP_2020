{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#read dataset\n",
    "\n",
    "names = [\"Vinit\",\"Shourish\",\"Mihir\",\"Parth\"]\n",
    "# gestures = [\"up\",\"right\",\"select\",\"stationary1\",\"stationary2\"] #except downleft\n",
    "# gestures = [\"up\",\"right\",\"down\",\"select\",\"stationary1\",\"stationary2\"] #with down\n",
    "gestures = [\"up\",\"right\",\"left\",\"down\",\"select\",\"stationary1\",\"stationary2\"] #allgest alldata\n",
    "# gestures = [\"up\",\"right\",\"left\",\"down\",\"select\",\"stationary1\",\"stationary2\"]\n",
    "\n",
    "images_pername_pergest  = 100\n",
    "\n",
    "N = 2*100*len(gestures)+2*200*len(gestures)\n",
    "dataset = np.zeros((N, 250, 170, 3), np.uint8)\n",
    "\n",
    "d_index = 0\n",
    "labels = np.zeros((N,1), np.int8)\n",
    "\n",
    "for gest in gestures:\n",
    "    for name in names:\n",
    "        if (name == \"Vinit\"and gest != \"left\") or name ==\"Mihir\":\n",
    "            for i in range(100):\n",
    "                img  = cv2.imread(fr\"E:\\USERS\\VINIT\\Desktop\\MainProject\\datasetColor\\{name}\\{gest}\\{name}_{i}.png\")\n",
    "                dataset[d_index] = img\n",
    "                labels[d_index] = gestures.index(gest)\n",
    "                d_index += 1\n",
    "        elif name==\"Parth\" or name==\"Shourish\":\n",
    "            for i in range(100):\n",
    "                img  = cv2.imread(fr\"E:\\USERS\\VINIT\\Desktop\\MainProject\\datasetColor\\{name}\\{gest}\\{name}_{i}.png\")\n",
    "                dataset[d_index] = img\n",
    "                labels[d_index] = gestures.index(gest)\n",
    "                d_index += 1\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Normalisation and Dividing the set\n",
    "dataset = dataset/255\n",
    "X_train,X_test,y_train,y_test=train_test_split(dataset,labels,test_size=0.10,shuffle=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = \"Vinit\"\n",
    "# gest = \"up\"\n",
    "# i = 100\n",
    "# img  = cv2.imread(fr\"E:\\USERS\\VINIT\\Desktop\\MainProject\\datasetColor\\{name}\\{gest}\\{name}_{i}.png\")\n",
    "# # type(img)\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Architecture & Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Model2\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.AveragePooling2D(6,3, input_shape=(250,170,3)),\n",
    "    keras.layers.Conv2D(512, 3, activation='relu'),\n",
    "    keras.layers.Conv2D(256, 3, activation='relu'),\n",
    "    keras.layers.Conv2D(128, 3, activation='relu'),\n",
    "    keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    keras.layers.MaxPool2D(2,2),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(len(gestures), activation='softmax')\n",
    " ])\n",
    "\n",
    "model.compile(optimizer='adam',loss=keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=20)\n",
    "# tf.keras.utils.plot_model(model, to_file=\"image.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dataset[1]\n",
    "a = a.reshape(1,250,170,3)\n",
    "model.predict_classes(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def main():\n",
    "    cap=cv2.VideoCapture(0)\n",
    "    mfound=False\n",
    "    one=False\n",
    "    i=0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        roi=frame[150:400,450:620]/255\n",
    "        cv2.rectangle(frame, (450,150), (620,400), (255,255,255))\n",
    "\n",
    "        \n",
    "        prediction=model.predict_classes(roi.reshape(1,250,170,3))    \n",
    "        font =cv2.FONT_HERSHEY_COMPLEX\n",
    "        cv2.putText(frame, \"THIS IS \"+gestures[prediction[0]], (0,200), font, 2, (255,255,0), 2)\n",
    "        cv2.imshow(\"frame\", frame)\n",
    "\n",
    "        inp=cv2.waitKey(1)\n",
    "        if inp==27:\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "            \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"colour.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('tf-gpu': conda)",
   "name": "python377jvsc74a57bd0ae94ca85d58db6b044464d6990840efcbd401058b14a736c486cb43f7024f76c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
